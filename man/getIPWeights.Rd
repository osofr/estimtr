% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/main_estimation.R
\name{getIPWeights}
\alias{getIPWeights}
\title{Inverse Probability Weights.}
\usage{
getIPWeights(
  OData,
  intervened_TRT = NULL,
  intervened_MONITOR = NULL,
  useonly_t_TRT = NULL,
  useonly_t_MONITOR = NULL,
  rule_name = paste0(c(intervened_TRT, intervened_MONITOR), collapse = ""),
  tmax = NULL,
  ignore_tmin = NULL,
  ignore_tmax = NULL,
  reverse_wt_prod = FALSE,
  holdout = FALSE,
  eval_stabP = TRUE,
  trunc_weights = Inf,
  intervened_type_TRT = NULL,
  intervened_type_MONITOR = NULL
)
}
\arguments{
\item{OData}{Input data object created by \code{importData} function.}

\item{intervened_TRT}{Column name in the input data with the probabilities (or indicators) of counterfactual
treatment nodes being equal to 1 at each time point.
Leave the argument unspecified (\code{NULL}) when not intervening on treatment node(s).}

\item{intervened_MONITOR}{Column name in the input data with probabilities (or indicators) of counterfactual
monitoring nodes being equal to 1 at each time point.
Leave the argument unspecified (\code{NULL}) when not intervening on the monitoring node(s).}

\item{useonly_t_TRT}{Use for intervening only on some subset of observation and time-specific treatment nodes.
Should be a character string with a logical expression that defines the subset of intervention observations.
For example, using \code{"TRT == 0"} will intervene only at observations with the value of \code{TRT} being
equal to zero.
The expression can contain any variable name that was defined in the input dataset.
Leave as \code{NULL} when intervening on all observations/time-points.}

\item{useonly_t_MONITOR}{Same as \code{useonly_t_TRT}, but for monitoring nodes.}

\item{rule_name}{Optional name for the treatment/monitoring regimen.}

\item{tmax}{Maximum value of the follow-up period.
All person-time observations above this value will be excluded from the output weights dataset.}

\item{ignore_tmin}{(ADVANCED FEATURE) Minimum value of the follow-up period at which the IP-weights should start accumulating over time.
All IP-weights for time-points t < ignore_tmin will be set to a constant 1.
This will have the effect of completely ignoring all weight contributions that occur before ignore_tmin.}

\item{ignore_tmax}{(ADVANCED FEATURE) Maximum value of the follow-up period to start accumulative the weights over time.
All of the time-specific IP-weights with t < ignore_tmin will be set to constant 1 PRIOR to the evaluation of the cumulative weights.
This will have the effect of completely ignoring all the IP weight contributions up to and including the time-point ignore_tmin.}

\item{reverse_wt_prod}{Set to TRUE to take the product of the cumulative weights in reverse time-ordering. That is, the
cumulative product will be evaluated by starting from the highest follow-up time point (time variable value).}

\item{holdout}{Obtain the weights based on out-of-sample (holdout / validation set) predictions of propensity scores.
This is useful for running CV-TMLE or evaluating the quality of the model fits based on validation sets.}

\item{eval_stabP}{Evaluate the additional weight stabilization factor for each time-point.
This is used for MSMs only and is enabled by default.}

\item{trunc_weights}{Specify the numeric weight truncation value. All final weights exceeding the value in
\code{trunc_weights} will be truncated.}

\item{intervened_type_TRT}{(ADVANCED FUNCTIONALITY) Set to \code{NULL} by default, can be characters that are set to either 
\code{"bin"}, \code{"shift"} or \code{"MSM"}. 
Provides support for different types of interventions on \code{TRT} (treatment) node (counterfactual treatment node \code{A^*(t)}).
The default behavior is the same as \code{"bin"}, which assumes that \code{A^*(t)} is binary and 
is set equal to either \code{0}, \code{1} or \code{p(t)}, where 0<=\code{p(t)}<=1. 
Here, \code{p(t)} denotes the probability that counterfactual A^*(t) is equal to 1, i.e., P(A^*(t)=1)=\code{p(t)} 
and it can change in time and subject to subject.
For \code{"shift"}, it is assumed that the intervention node \code{A^*(t)} is a shift in the value of the continuous treatment \code{A}, 
i.e., \code{A^*(t)}=\code{A(t)}+delta(t).
Finally, for "MSM" it is assumed that we simply want the final intervention density \code{g^*(t)} to be set to a constant 1. 
This has use for static MSMs.}

\item{intervened_type_MONITOR}{(ADVANCED FUNCTIONALITY) Same as \code{intervened_type_TRT}, but for monitoring intervention node 
(counterfactual monitoring node \code{N^*(t)}).}
}
\value{
A \code{data.table} with cumulative weights for each subject and each time-point saved under column "cum.IPAW".
}
\description{
Evaluate the inverse probability weights for up to 3 intervention nodes: \code{CENS}, \code{TRT} and \code{MONITOR}.
This is based on the inverse of the propensity score fits for the observed likelihood (g0.C, g0.A, g0.N),
multiplied by the indicator of not being censored and the probability of each intervention in \code{intervened_TRT}
and \code{intervened_MONITOR}.
Requires column name(s) that specify the counterfactual node values or the counterfactual probabilities of each
node being 1 (for stochastic interventions).
The output is person-specific data with evaluated weights, \code{wts.DT}, only observation-times with non-zero
weight are kept
Can be one regimen per single run of this block, which are then combined into a list of output datasets with lapply.
Alternative is to allow input with several rules/regimens, which are automatically combined into a list of output datasets.
}
\examples{
options(stremr.verbose = TRUE)
require("data.table")

# ----------------------------------------------------------------------
# Simulated Data
# ----------------------------------------------------------------------
data(OdataNoCENS)
OdataDT <- as.data.table(OdataNoCENS, key=c("ID", "t"))

# define lagged N, first value is always 1 (always monitored at the first time point):
OdataDT[, ("N.tminus1") := shift(get("N"), n = 1L, type = "lag", fill = 1L), by = ID]
OdataDT[, ("TI.tminus1") := shift(get("TI"), n = 1L, type = "lag", fill = 1L), by = ID]

# ----------------------------------------------------------------------
# Define intervention (always treated):
# ----------------------------------------------------------------------
OdataDT[, ("TI.set1") := 1L]
OdataDT[, ("TI.set0") := 0L]

# ----------------------------------------------------------------------
# Import Data
# ----------------------------------------------------------------------
OData <- importData(OdataDT, ID = "ID", t = "t", covars = c("highA1c", "lastNat1", "N.tminus1"),
                    CENS = "C", TRT = "TI", MONITOR = "N", OUTCOME = "Y.tplus1")

# ----------------------------------------------------------------------
# Look at the input data object
# ----------------------------------------------------------------------
print(OData)

# ----------------------------------------------------------------------
# Access the input data
# ----------------------------------------------------------------------
get_data(OData)

# ----------------------------------------------------------------------
# Model the Propensity Scores
# ----------------------------------------------------------------------
gform_CENS <- "C ~ highA1c + lastNat1"
gform_TRT = "TI ~ CVD + highA1c + N.tminus1"
gform_MONITOR <- "N ~ 1"
stratify_CENS <- list(C=c("t < 16", "t == 16"))

# ----------------------------------------------------------------------
# Fit Propensity Scores
# ----------------------------------------------------------------------
OData <- fitPropensity(OData, gform_CENS = gform_CENS,
                        gform_TRT = gform_TRT,
                        gform_MONITOR = gform_MONITOR,
                        stratify_CENS = stratify_CENS)

# ----------------------------------------------------------------------
# IPW Ajusted KM or Saturated MSM
# ----------------------------------------------------------------------
require("magrittr")
AKME.St.1 <- getIPWeights(OData, intervened_TRT = "TI.set1") \%>\%
             survNPMSM(OData) \%$\%
             estimates
AKME.St.1

# ----------------------------------------------------------------------
# Bounded IPW
# ----------------------------------------------------------------------
IPW.St.1 <- getIPWeights(OData, intervened_TRT = "TI.set1") \%>\%
            directIPW(OData)
IPW.St.1[]

# ----------------------------------------------------------------------
# IPW-MSM for hazard
# ----------------------------------------------------------------------
wts.DT.1 <- getIPWeights(OData = OData, intervened_TRT = "TI.set1", rule_name = "TI1")
wts.DT.0 <- getIPWeights(OData = OData, intervened_TRT = "TI.set0", rule_name = "TI0")
survMSM_res <- survMSM(list(wts.DT.1, wts.DT.0), OData, tbreaks = c(1:8,12,16)-1,)
survMSM_res$St

# ----------------------------------------------------------------------
# Sequential G-COMP
# ----------------------------------------------------------------------
t.surv <- c(0:10)
Qforms <- rep.int("Qkplus1 ~ CVD + highA1c + N + lastNat1 + TI + TI.tminus1", (max(t.surv)+1))
params <- gridisl::defModel(estimator = "speedglm__glm")

\dontrun{
gcomp_est <- fit_GCOMP(OData, tvals = t.surv, intervened_TRT = "TI.set1",
                          Qforms = Qforms, models = params, stratifyQ_by_rule = FALSE)
gcomp_est[]
}
# ----------------------------------------------------------------------
# TMLE
# ----------------------------------------------------------------------
\dontrun{
tmle_est <- fit_TMLE(OData, tvals = t.surv, intervened_TRT = "TI.set1",
                    Qforms = Qforms, models = params, stratifyQ_by_rule = TRUE)
tmle_est[]
}

# ----------------------------------------------------------------------
# Running IPW-Adjusted KM with optional user-specified weights:
# ----------------------------------------------------------------------
addedWts_DT <- OdataDT[, c("ID", "t"), with = FALSE]
addedWts_DT[, new.wts := sample.int(10, nrow(OdataDT), replace = TRUE)/10]
survNP_res_addedWts <- survNPMSM(wts.DT.1, OData, weights = addedWts_DT)

# ----------------------------------------------------------------------
# Multivariate Propensity Score Regressions
# ----------------------------------------------------------------------
gform_CENS <- "C + TI + N ~ highA1c + lastNat1"
OData <- fitPropensity(OData, gform_CENS = gform_CENS, gform_TRT = gform_TRT,
                        gform_MONITOR = gform_MONITOR)

# ----------------------------------------------------------------------
# Fitting treatment model with Gradient Boosting machines:
# ----------------------------------------------------------------------
\dontrun{
require("h2o")
h2o::h2o.init(nthreads = -1)
gform_CENS <- "C ~ highA1c + lastNat1"
models_TRT <- sl3::Lrnr_h2o_grid$new(algorithm = "gbm")
OData <- fitPropensity(OData, gform_CENS = gform_CENS,
                        gform_TRT = gform_TRT,
                        models_TRT = models_TRT,
                        gform_MONITOR = gform_MONITOR,
                        stratify_CENS = stratify_CENS)

# Use `H2O-3` distributed implementation of GLM for treatment model estimator:
models_TRT <- sl3::Lrnr_h2o_glm$new(family = "binomial")
OData <- fitPropensity(OData, gform_CENS = gform_CENS,
                        gform_TRT = gform_TRT,
                        models_TRT = models_TRT,
                        gform_MONITOR = gform_MONITOR,
                        stratify_CENS = stratify_CENS)

# Use Deep Neural Nets:
models_TRT <- sl3::Lrnr_h2o_grid$new(algorithm = "deeplearning")
OData <- fitPropensity(OData, gform_CENS = gform_CENS,
                        gform_TRT = gform_TRT,
                        models_TRT = models_TRT,
                        gform_MONITOR = gform_MONITOR,
                        stratify_CENS = stratify_CENS)
}

# ----------------------------------------------------------------------
# Fitting different models with different algorithms
# Fine tuning modeling with optional tuning parameters.
# ----------------------------------------------------------------------
\dontrun{
params_TRT <- sl3::Lrnr_h2o_grid$new(algorithm = "gbm",
                              ntrees = 50,
                              learn_rate = 0.05,
                              sample_rate = 0.8,
                              col_sample_rate = 0.8,
                              balance_classes = TRUE)
params_CENS <- sl3::Lrnr_glm_fast$new()
params_MONITOR <- sl3::Lrnr_glm_fast$new()
OData <- fitPropensity(OData,
            gform_CENS = gform_CENS, stratify_CENS = stratify_CENS, params_CENS = params_CENS,
            gform_TRT = gform_TRT, params_TRT = params_TRT,
            gform_MONITOR = gform_MONITOR, params_MONITOR = params_MONITOR)
}

# ----------------------------------------------------------------------
# Running TMLE based on the previous fit of the propensity scores.
# Also applying Random Forest to estimate the sequential outcome model
# ----------------------------------------------------------------------
\dontrun{
t.surv <- c(0:5)
Qforms <- rep.int("Qkplus1 ~ CVD + highA1c + N + lastNat1 + TI + TI.tminus1", (max(t.surv)+1))
models <- sl3::Lrnr_h2o_grid$new(algorithm = "randomForest",
                           ntrees = 100, learn_rate = 0.05, sample_rate = 0.8,
                           col_sample_rate = 0.8, balance_classes = TRUE)
tmle_est <- fit_TMLE(OData, tvals = t.surv, intervened_TRT = "TI.set1",
            Qforms = Qforms, models = models,
            stratifyQ_by_rule = TRUE)
}

\dontrun{
t.surv <- c(0:5)
Qforms <- rep.int("Qkplus1 ~ CVD + highA1c + N + lastNat1 + TI + TI.tminus1", (max(t.surv)+1))
models <- sl3::Lrnr_h2o_grid$new(algorithm = "randomForest",
                           ntrees = 100, learn_rate = 0.05, sample_rate = 0.8,
                           col_sample_rate = 0.8, balance_classes = TRUE)
tmle_est <- fit_TMLE(OData, tvals = t.surv, intervened_TRT = "TI.set1",
            Qforms = Qforms, models = models,
            stratifyQ_by_rule = FALSE)
}

}
